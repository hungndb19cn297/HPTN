{"content":"<h1 id=\"1giithiu\">1. GI·ªöI THI·ªÜU</h1><p>Trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y, v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa c√°c m√¥ h√¨nh <strong>Generative model</strong> c√°c ·ª©ng d·ª•ng t·ª± sinh d·ªØ li·ªáu text, video, ·∫£nh c√†ng tr·ªü n√™n nhi·ªÅu h∆°n. C√°c ·ª©ng d·ª•ng ch·ªânh s·ª≠a ·∫£nh v√† l√†m ƒë·∫πp c≈©ng ƒë∆∞·ª£c ch√∫ tr·ªçng tr√™n c√°c ·ª©ng d·ª•ng app, web nh∆∞:  <a href=\"https://play.google.com/store/apps/details?id=com.instashot.camerashot.mediaidea\">TakeShot AI Video Photo Editor</a> , faceapp, gradient, Perfect365 Makeup, Beauty Makeup, facetune2 m·ª•c ti√™u ƒë·ªÉ c√≥ nh·ªØng b·ª©c ·∫£nh ƒëep chia s·∫ª tr√™n m·∫°ng x√£ h·ªôi. Trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω chia s·∫ª v·ªÅ c√°ch ƒë·ªÉ t·ª± sinh ra nh·ªØng b·ª©c ·∫£nh avatar t·ª´ AI s·ª≠ d·ª•ng stable diffusion.<br/>Let go!!!!</p><h1 id=\"2tvn\">2. ƒê·∫∂T V·∫§N ƒê·ªÄ</h1><p>Tr∆∞·ªõc khi tri·ªÉn khai, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu qua v·ªÅ m√¥ h√¨nh Stable Diffusion v√† ti·ªÅn th√¢n c·ªßa n√≥ l√† m√¥ h√¨nh Diffusion nh√©.</p><h2 id=\"21mhnhdiffusion\">2.1. M√¥ h√¨nh Diffusion</h2><p>Diffusion Models (DMs) l√† m·ªôt m√¥ h√¨nh x√°c su·∫•t, ho·∫°t ƒë·ªông b·∫±ng c√°ch ·ª©ng d·ª•ng Unet kh·ª≠ nhi·ªÖu l·∫∑p ƒëi l·∫∑p l·∫°i nhi·ªÅu l·∫ßn ƒë·ªÉ t·∫°o ra ·∫£nh th·ª±c t·ª´ nhi·ªÖu. <br/>Qu√° tr√¨nh hu·∫•n luy·ªán c·ªßa m√¥ h√¨nh diffusion bao g·ªìm hai giai ƒëo·∫°n:</p><ul><li>Forward Diffusion Process: M√¥ h√¨nh s·∫Ω ƒë∆∞·ª£c hu·∫•n luy·ªán t·ª´ ·∫£nh ban ƒë·∫ßu v·ªõi k√≠ch th∆∞·ªõc <strong>512*512pixel</strong> c√πng v·ªõi qu√° tr√¨nh khu·∫•n t√°n thu·∫≠n, m√¥ h√¨nh s·∫Ω th√™m nhi·ªÖu (noise) theo ph√¢n ph·ªëi $q(x<em>{1:T} | x</em>0)$ cho ƒë·∫øn khi ƒë·∫ßu ra l√† m·ªôt ·∫£nh to√†n nhi·ªÖu.</li><li>Reverse Diffusion Process: kh·ª≠ nhi·ªÖu t·ª´ ·∫£nh t·ª´ng b∆∞·ªõc m·ªôt theo ph√¢n ph·ªëi $p<em>{\\theta}(x</em>{0:T})$, ƒë√¢y ch√≠nh l√† giai ƒëo·∫°n m√† m√¥ h√¨nh diffusion s·∫Ω t√¨m c√°ch h·ªçc ƒë·ªÉ ƒë·∫£o ng∆∞·ª£c qu√° tr√¨nh th√™m nhi·ªÖu v√†o trong ·∫£nh, t·ª´ ƒë√≥ c√≥ th·ªÉ t·∫°o ra ·∫£nh th·ª±c t·ª´ nhi·ªÖu.</li></ul><p><img src=\"https://images.viblo.asia/cee14713-e03b-427d-a0d3-a278e5947430.png\" alt=\"image.png\" /> </p><p>&lt;div align=\"center\"&gt;H√¨nh 1: H√¨nh ·∫£nh m√¥ h√¨nh diffusion<br/>&lt;/div&gt;</p><p>M√¥ h√¨nh diffusion cho k·∫øt qu·∫£ t·ªët so c√°c generative models nh∆∞ GAN, VAE, tuy nhi√™n m√¥ t·∫£ cho ƒë·∫øn nay s·∫Ω t·∫°o ra h√¨nh ·∫£nh nh∆∞ng kh√¥ng s·ª≠ d·ª•ng b·∫•t k·ª≥  ƒëi·ªÅu ki·ªán r√†ng bu·ªôc n√†o. V√¨ v·∫≠y, n·∫øu ch√∫ng ta tri·ªÉn khai m√¥ h√¨nh n√†y, n√≥ s·∫Ω t·∫°o ra nh·ªØng h√¨nh ·∫£nh ƒë·∫πp m·∫Øt, nh∆∞ng kh√¥ng c√≥ c√°ch n√†o ki·ªÉm so√°t. ƒê·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ m√¥ h√¨nh b·∫°n c√≥ th·ªÉ tham kh·∫£o: <a href=\"https://arxiv.org/abs/2006.11239\">Denoising Diffusion Probabilistic Models</a> .</p><h2 id=\"22mhnhstablediffusion\">2.2 M√¥ h√¨nh Stable Diffusion</h2><p>Stable Diffusion (Latent Diffusion Model) ƒë∆∞·ª£c gi·ªõi thi·ªáu trong b√†i b√°o <a href=\"https://arxiv.org/abs/2112.10752\">High-Resolution Image Synthesis with Latent Diffusion Models (Rombach et al., 2022)</a> v√† ƒë·∫°t k·∫øt qu·∫£ t∆∞∆°ng ƒë·ªëi t·ªët tr√™n nhi·ªÅu t√°c v·ª• kh√°c nhau nh∆∞ unconditional image generation (sinh ·∫£nh kh√¥ng ƒëi·ªÅu ki·ªán), semantic scene synthesis (sinh ·∫£nh t·ª´ segmentation mask), and super-resolution (tƒÉng ƒë·ªô ph√¢n gi·∫£i cho ·∫£nh), trong khi ch·∫°y nhanh h∆°n v√† c·∫ßn √≠t t√†i nguy√™n t√≠nh to√°n h∆°n so v·ªõi m√¥ h√¨nh diffusion g·ªëc. ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥ th√¨ Stable Diffusion s·ª≠ d·ª•ng ph·∫ßn encoder c·ªßa m·ªôt autoencoder ƒë·ªÉ n√©n ·∫£nh d∆∞·ªõi d·∫°ng lower-dimensional representations (bi·ªÉu di·ªÖn √≠t chi·ªÅu h∆°n) trong kh√¥ng gian pixel m√¥ t·∫£ nh∆∞ h√¨nh v√†  latent space (kh√¥ng gian d·ªØ li·ªáu ·∫©n), r·ªìi cho qua qu√° tr√¨nh t∆∞∆°ng t·ª± nh∆∞ ·∫£nh trong m√¥ h√¨nh diffusion g·ªëc, sau ƒë√≥ s·ª≠ d·ª•ng ph·∫ßn decoder c·ªßa autoencoder ƒë·ªÉ gi·∫£i n√©n latent data tr·ªü v·ªÅ ·∫£nh.</p><p><img src=\"https://images.viblo.asia/ed474bac-123a-42b2-9097-a3196f4494d3.png\" alt=\"Screenshot from 2023-08-10 17-44-41.png\" /></p><p>&lt;div align=\"center\"&gt;H√¨nh 2. M√¥ h√¨nh Stable Diffusion&lt;/div&gt;</p><p>Ta c√≥ th·∫ø nh·∫≠n th·∫•y ·ªü m·ª•c 2.1 m√¥ h√¨nh diffusion Unet kh√¥ng s·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán(conditioning) ƒë·∫ßu v√†o v√† ƒë·∫ßu ra s·∫Ω nh∆∞ h√¨nh:</p><p><img src=\"https://images.viblo.asia/1103ca2c-7df0-4858-a2be-8d0d79e512eb.png\" alt=\"image.png\" /></p><p>&lt;div align=\"center\"&gt;H√¨nh 3. C√°c l·ªõp c·ªßa b·ªô d·ª± ƒëo√°n nhi·ªÖu Unet (kh√¥ng c√≥ ƒëi·ªÅu ki·ªán)&lt;/div&gt;<br/>B√™n trong, ch√∫ng ta th·∫•y r·∫±ng:</p><ul><li>Unet l√† m·ªôt lo·∫°t c√°c l·ªõp ƒë·ªÉ bi·∫øn ƒë·ªïi m·∫£ng latent</li><li>M·ªói l·ªõp th·ª±c hi·ªán bi·∫øn ƒë·ªïi tr√™n ƒë·∫ßu ra c·ªßa l·ªõp tr∆∞·ªõc</li><li>M·ªôt s·ªë ƒë·∫ßu ra ƒë∆∞·ª£c chuy·ªÉn ti·∫øp (th√¥ng qua c√°c k·∫øt n·ªëi residual) v√†o qu√° tr√¨nh x·ª≠ l√Ω sau ƒë√≥ trong m·∫°ng.</li><li>Timestep ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh m·ªôt timestep embedding vector v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c l·ªõp.</li></ul><p>C√≤n v·ªõi Stable Diffusion c√≤n cho ph√©p sinh ·∫£nh t·ª´ text prompts (ƒëo·∫°n vƒÉn m√¥ t·∫£) b·∫±ng c√°ch chuy·ªÉn ch√∫ng th√†nh text embeddings th√¥ng qua vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ (v√≠ d·ª• nh∆∞ BERT, CLIP) r·ªìi ƒë∆∞a ch√∫ng v√†o trong Unet th√¥ng qua multihead attention layer. M√¥ h√¨nh cho ph√©p s√°ng t·∫°o n·ªôi dung d·ª±a tr√™n prompt t·ª´ ng∆∞·ªùi d√πng.</p><p><img src=\"https://images.viblo.asia/6a6793e4-7cd5-46f6-9ec6-41d049554fff.png\" alt=\"image.png\" /></p><p>&lt;div align=\"center\"&gt;H√¨nh 4. C√°c l·ªõp c·ªßa b·ªô d·ª± ƒëo√°n nhi·ªÖu Unet (c√≥ ƒëi·ªÅu ki·ªán)&lt;/div&gt;</p><h1 id=\"3trinkhaibiton\">3 TRI·ªÇN KHAI B√ÄI TO√ÅN</h1><h2 id=\"31chunbdliu\">3.1. Chu·∫©n b·ªã d·ªØ li·ªáu</h2><p>ƒê·ªÉ c√≥ k·∫øt qu·∫£ t·ªët cho vi·ªác training th√¨ vi·ªác chu·∫©n b·ªã d·ªØ li·ªáu ·∫£nh ƒë·∫ßu v√†o l√† quan tr·ªçng. ƒê·ªÉ c√≥ th·ªÉ sinh ·∫£nh gi·ªëng v·ªõi ch·ªß th·ªÉ trong khung h√¨nh b·∫°n c·∫ßn chu·∫©n b·ªã m·ªôt th∆∞ vi·ªán ·∫£nh g·ªìm 10 -20 h√¨nh ·∫£nh th·∫≠t r√µ n√©t v√† ch·ª•p c√°c g√≥c c·∫°nh kh√°c nhau c·ªßa ƒë·ªëi t∆∞·ª£ng, ch·ªß th·ªÉ v√† trong nh·ªØng background kh√°c nhau. H√£y ƒë·∫£m b·∫£o r·∫±ng t·∫≠p h√¨nh ·∫£nh c·ªßa b·∫°n s·∫Ω c√≥ k√≠ch th∆∞·ªõc  <strong>512x512pixel</strong> , ƒë·ªÉ chuy·ªÉn h√¨nh ·∫£nh b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng web resize ·∫£nh online <a href=\"https://www.birme.net/?no_resize=true&amp;auto_focal=false\">BIRME</a> nh∆∞ h√¨nh 5</p><p><img src=\"https://images.viblo.asia/92b0391a-a6f0-4490-b2fb-87852f00ab50.png\" alt=\"image.png\" /></p><p>&lt;div align=\"center\"&gt;H√¨nh 5. D·ªØ li·ªáu h√¨nh ·∫£nh crop v·ªÅ k√≠ch th∆∞·ªõc 512x512pixel&lt;/div&gt;</p><h2 id=\"32training\">3.2. Training</h2><p>M√¨nh s·ª≠ d·ª•ng Google Colab trong qu√° tr√¨nh training m√¥ h√¨nh DreamBooth t·ª± sinh v·ªõi ch√≠nh t·∫≠p d·ªØ li·ªáu c·ªßa m√¨nh v√† ƒë·ªÉ kh√¥ng b·ªã ng·∫Øt k·∫øt n·ªëi b·∫°n n√™n d√πng t√†i kho·∫£n gmail m·ªõi ƒë·ªÉ th·ª±c hi·ªán, ho·∫∑c b·∫°n c√≥ th·ªÉ n√¢ng c·∫•p l√™n g√≥i Google Colab Pro n·∫øu c·∫ßn ƒë√†o t·∫°o d·ªØ li·ªáu l·ªõn h∆°n. Link Google Colab m√¨nh ƒë·ªÉ ·ªü d∆∞·ªõi: <a href=\"https://colab.research.google.com/github/FurkanGozukara/Stable-Diffusion/blob/main/DreamBooth/ShivamShriraoDreamBooth.ipynb#scrollTo=5vDpCxId1aCm\">source code</a>Ch√∫ng ta c√πng ƒëi v√†o th·ª±c hi·ªán th√¥i n√†o üòÅüòÅüòÅ</p><h3 id=\"bc1ktningoogledrive\">B∆∞·ªõc 1: K·∫øt n·ªëi ƒë·∫øn Google Drive</h3><pre><code>from google.colab import drive<br/>drive.mount('/content/drive')<br/></code></pre><h3 id=\"bc2citccthvincnthit\">B∆∞·ªõc 2: C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt</h3><pre><code>!wget -q https://gist.githubusercontent.com/FurkanGozukara/be7be5f9f7820d0bb85a3052874f184e/raw/d8d179da6cab0735bd5832029c2dec5163db87b4/train_dreambooth.py<br/>!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py<br/>%pip install -qq git+https://github.com/ShivamShrirao/diffusers<br/>%pip install -q -U --pre triton<br/>%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers<br/>%pip uninstall torch -y<br/>%pip uninstall torchvision -y<br/>%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118<br/></code></pre><h3 id=\"bc3downloadstablediffusionweights\">B∆∞·ªõc 3:  Download Stable Diffusion weights</h3><p>B·∫°n c·∫ßn ƒëƒÉng k√Ω t√†i kho·∫£n  <strong>HuggingFace</strong> ü§ó ƒë·ªÉ c√≥ th·ªÉ t·∫£i v·ªÅ c√°c file Stable Diffusion weights.</p><pre><code>MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}<br/>#@markdown Enter the directory name to save model at.<br/>OUTPUT_DIR = \"stable_diffusion_weights/ohwx\" #@param {type:\"string\"}<br/>if save_to_gdrive:<br/>    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR<br/>else:<br/>    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR<br/>print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")<br/>!mkdir -p $OUTPUT_DIR<br/></code></pre><p>·ªû b√†i vi·∫øt n√†y m√¨nh s·ª≠ d·ª•ng model <strong>stable-diffusion-v1-5</strong>, sau khi t·∫£i v·ªÅ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o google drive v·ªõi ƒë∆∞·ªùng d·∫´n l√† <em>OUTPUTDIR</em></p><h3 id=\"bc4cuhnhfileconfig\">B∆∞·ªõc 4:  C·∫•u h√¨nh file config</h3><p>Ph·∫ßn n√†y kh√° quan tr·ªçng v√¨ n√≥ ƒë·ªãnh nghƒ©a ƒë·ªëi t∆∞·ª£ng ch·ªß th·ªÉ nh∆∞ v√≠ d·ª•: ƒë·ªëi t∆∞·ª£ng l√† <em>hoanganh</em> v√† class_prompt l√† <em>person</em>.</p><pre><code>concepts_list = [<br/>    {<br/>        \"instance_prompt\":      \"hoanganh\",<br/>        \"class_prompt\":         \"person\",<br/>        \"instance_data_dir\":    \"/content/data/hoanganh\",<br/>        \"class_data_dir\":       \"/content/data/persion\"<br/>    },<br/>]<br/># `class_data_dir` contains regularization images<br/>import json<br/>import os<br/>for c in concepts_list:<br/>    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)<br/>with open(\"concepts_list.json\", \"w\") as f:<br/>    json.dump(concepts_list, f, indent=4)<br/></code></pre><h3 id=\"bc5training\">B∆∞·ªõc 5:  Training</h3><p>Qu√° tr√¨nh training model s·ª≠ d·ª•ng Dreambooth trong Stable Diffusion l√† m·ªôt trong nh·ªØng c√°ch ƒë·ªÉ gi√∫p b·∫°n c√≥ m·ªôt b·ªô m√¥ h√¨nh ri√™ng c·ªßa c√° nh√¢n m√¨nh. Th√¥ng th∆∞·ªùng b·∫°n s·∫Ω ph·∫£i t·∫£i c√°c model checkpoint hay lora ƒë∆∞·ª£c chia s·∫ª tr√™n c·ªông ƒë·ªìng m·∫°ng ƒë·ªÉ v·∫Ω tranh AI trong SD. Nh∆∞ng v·ªõi vi·ªác train Dreambooth b·∫°n s·∫Ω th·ªèa s·ª©c s√°ng t·∫°o, v√† t·∫°o ra nh·ªØng h√¨nh ·∫£nh AI theo phong c√°ch c·ªßa b·∫°n.</p><pre><code>!python3 train_dreambooth.py \\<br/>  --pretrained_model_name_or_path=$MODEL_NAME \\<br/>  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\<br/>  --output_dir=$OUTPUT_DIR \\<br/>  --revision=\"fp16\" \\<br/>  --with_prior_preservation --prior_loss_weight=1.0 \\<br/>  --seed=1337 \\<br/>  --resolution=512 \\<br/>  --train_batch_size=1 \\<br/>  --train_text_encoder \\<br/>  --mixed_precision=\"fp16\" \\<br/>  --use_8bit_adam \\<br/>  --gradient_accumulation_steps=1 \\<br/>  --learning_rate=1e-6 \\<br/>  --lr_scheduler=\"constant\" \\<br/>  --lr_warmup_steps=0 \\<br/>  --num_class_images=50 \\<br/>  --sample_batch_size=1 \\<br/>  --max_train_steps=800 \\<br/>  --save_interval=10000 \\<br/>  --save_sample_prompt=\"hoanganh person\" \\<br/>  --concepts_list=\"concepts_list.json\"<br/></code></pre><h3 id=\"bc6previewktqusaukhioto\">B∆∞·ªõc 6:  Preview k·∫øt qu·∫£ sau khi ƒë√†o t·∫°o</h3><pre><code>import os<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>weights_folder = OUTPUT_DIR<br/>folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))<br/>row = len(folders)<br/>col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))<br/>scale = 4<br/>fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})<br/>for i, folder in enumerate(folders):<br/>    folder_path = os.path.join(weights_folder, folder)<br/>    image_folder = os.path.join(folder_path, \"samples\")<br/>    images = [f for f in os.listdir(image_folder)]<br/>    for j, image in enumerate(images):<br/>        if row == 1:<br/>            currAxes = axes[j]<br/>        else:<br/>            currAxes = axes[i, j]<br/>        if i == 0:<br/>            currAxes.set_title(f\"Image {j}\")<br/>        if j == 0:<br/>            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)<br/>        image_path = os.path.join(image_folder, image)<br/>        img = mpimg.imread(image_path)<br/>        currAxes.imshow(img, cmap='gray')<br/>        currAxes.axis('off')<br/>plt.tight_layout()<br/>plt.savefig('grid.png', dpi=72)<br/></code></pre><p>K·∫øt qu·∫£ l√† h√¨nh ·∫£nh c·ªßa ch·ªß th·ªÉ ƒë∆∞·ª£c sinh ra nh∆∞ h√¨nh 6</p><p><img src=\"https://images.viblo.asia/7b957c6b-4f12-4e82-a0d8-625393994f76.png\" alt=\"Screenshot from 2023-08-11 13-32-49.png\" /></p><p>&lt;div align=\"center\"&gt;H√¨nh 6. H√¨nh ch·ªß th·ªÉ ƒë∆∞·ª£c sinh ra&lt;/div&gt;</p><h3 id=\"bc7inference\">B∆∞·ªõc 7:  Inference</h3><p>S·ª≠ d·ª•ng model sau khi ƒë√£ training DreamBooth xong l√†m ƒë·∫ßu v√†o cho m√¥ h√¨nh Stable Diffusion n√†o. B·∫°n h√£y chu·∫©n b·ªã m·ªôt s·ªë prompt ƒë·ªÉ c√≥ th·ªÉ ki·ªÉm tra c√°c k·∫øt qu·∫£ tr·∫£ ra nh√©. C√≥ th·ªÉ tham kh·∫£o c√°c prompt free t·∫°i ƒë√¢y: <a href=\"https://lexica.art/\">lexica</a>.</p><pre><code>import torch<br/>from torch import autocast<br/>from diffusers import StableDiffusionPipeline, DDIMScheduler<br/>from IPython.display import display<br/>model_path = '/content/stable_diffusion_weights/ohwx/800'             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive<br/>pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")<br/>pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)<br/>pipe.enable_xformers_memory_efficient_attention()<br/>g_cuda = None<br/>prompt = \"photo of ohwx man in tomer hanuka style\" #@param {type:\"string\"}<br/>negative_prompt = \"\" #@param {type:\"string\"}<br/>num_samples = 4 #@param {type:\"number\"}<br/>guidance_scale = 7.5 #@param {type:\"number\"}<br/>num_inference_steps = 24 #@param {type:\"number\"}<br/>height = 512 #@param {type:\"number\"}<br/>width = 512 #@param {type:\"number\"}<br/>with autocast(\"cuda\"), torch.inference_mode():<br/>    images = pipe(<br/>        prompt,<br/>        height=height,<br/>        width=width,<br/>        negative_prompt=negative_prompt,<br/>        num_images_per_prompt=num_samples,<br/>        num_inference_steps=num_inference_steps,<br/>        guidance_scale=guidance_scale,<br/>        generator=g_cuda<br/>    ).images<br/>for img in images:<br/>    display(img)<br/></code></pre><p>Trong ƒë√≥:</p><ul><li>Prompt: l√† input ƒë·∫ßu v√†o ch√≠nh ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ h∆∞·ªõng d·∫´n vi·ªác t·∫°o ra h√¨nh ·∫£nh mong mu·ªën</li><li>height, width: k√≠ch th∆∞·ªõc h√¨nh ·∫£nh sinh ra t∆∞∆°ng ·ª©ng.</li><li>negative_prompt: c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ch·ªâ ra c√°c kh√≠a c·∫°nh m√† b·∫°n mu·ªën tr√°nh ho·∫∑c gi·∫£m thi·ªÉu trong c√°c h√¨nh ·∫£nh ƒë∆∞·ª£c t·∫°o ra. VD: \"bu·ªìn b√£\", \"n·ªÅn t·ªëi\", ‚Ä¶</li><li>num<em>images</em>per_prompt: s·ªë l∆∞·ª£ng ·∫£nh mong mu·ªën ƒë∆∞·ª£c sinh ra.</li><li>guidance_scale: l√† m·ªôt tham s·ªë ki·ªÉm so√°t m·ª©c ƒë·ªô qu√° tr√¨nh t·∫°o h√¨nh ·∫£nh tu√¢n theo prompt. Gi√° tr·ªã c√†ng cao, h√¨nh ·∫£nh c√†ng d√≠nh v√†o m·ªôt ƒë·∫ßu v√†o vƒÉn b·∫£n nh·∫•t ƒë·ªãnh</li></ul><p>ƒê√¢y l√† k·∫øt qu·∫£ AI Avatar c·ªßa m√¨nh sinh ra t·ª´ Stable Diffusion v·ªõi  8 m·∫´u prompt.</p><p><img src=\"https://images.viblo.asia/f63db10d-b27d-4013-8247-dac1527594e4.png\" alt=\"Screenshot from 2023-08-11 16-14-30.png\" /> </p><p>&lt;div align=\"center\"&gt;H√¨nh 7. K·∫øt qu·∫£ tr·∫£ tra sau khi qua Stable Diffusion&lt;/div&gt;</p><h1 id=\"4ktlun\">4. K·∫æT LU·∫¨N</h1><p>Tr√™n ƒë√¢y l√† h∆∞·ªõng d·∫´n v·ªÅ c√°ch s·ª≠ d·ª•ng Stable Diffusion sinh ra c√°c h√¨nh ·∫£nh Avatar theo mong mu·ªën c·ªßa m·ªçi ng∆∞·ªùi r·ªìi nh√©. <br/>H√£y t·∫≠n d·ª•ng h·∫øt s·ª©c m·∫°nh c·ªßa c√¥ng ngh·ªá tr√≠ tu·ªá nh√¢n t·∫°o A.I ƒë·ªÉ s√°ng t·∫°o ra b·∫•t c·ª© th·ª© g√¨ m√† b·∫°n th√≠ch. V·ªõi Dreambooth v√† Stable Diffusion h·ª©a h·∫πn s·∫Ω ƒë√≥ng g√≥p v√†o ph√°t tri·ªÉn c·ªßa c·ªông ƒë·ªìng Machine Learning v√† Deep Learning, gi√∫p c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y v√† ·ª©ng d·ª•ng c·ªßa ch√∫ng trong th·ª±c t·∫ø.</p><h1 id=\"5tiliuthamchiu\">5. T√ÄI LI·ªÜU THAM CHI·∫æU</h1><p>[1] <a href=\"https://trituenhantao.io/kien-thuc/minh-hoa-stable-diffusion/\">Minh H·ªça Stable Diffusion</a></p><p>[2] <a href=\"https://arxiv.org/abs/2006.11239\">Denoising Diffusion Probabilistic Models</a></p><p>[3] <a href=\"https://aichatgpt.vn/huong-dan-training-model-voi-dreambooth-trong-stable-diffusion/\">Dreambooth-trong-stable-diffusion</a></p><p>[4] <a href=\"https://theaisummer.com/diffusion-models/\">Diffusion models</a></p><p>[5] https://viblo.asia/p/paper-explain-high-resolution-image-synthesis-with-latent-diffusion-models-r1QLxPogLAw </p><p>[6] <a href=\"https://arxiv.org/abs/2112.10752\">High-Resolution Image Synthesis with Latent Diffusion Models</a></p><p>[7] <a href=\"https://arxiv.org/abs/2208.11970\">Understanding Diffusion Models: A Unified Perspective</a></p>","title":"[AI-Avatar] T·∫°o sinh Avatar c√πng v·ªõi Stable Diffusion","tags":["Deep Learning","Stable Diffusion","Generative Adversarial Network","Computer Vision","diffusion-model"],"created_at":1691746685000,"updated_at":1691983269000,"comments":[]}
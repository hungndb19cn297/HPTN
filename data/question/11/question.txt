{"content":"<p>Hello mọi người tiếp tục Series vén màn sự thật về Kafka của mình Link 👉️👉️👉️  <a href=\"https://viblo.asia/s/series-ven-man-su-that-ve-apache-kafka-PAoJe8vN41j\">tại đây </a>  dành cho ace mới đọc bài viết của mình lần đầu. </p><p>Và tiếp tục cho<a href=\"https://viblo.asia/p/kafka-connect-la-gi-minh-da-dung-kafka-connect-de-dong-bo-du-lieu-nhu-the-nao-phan-1-Ny0VGjX8LPA\"> bài trước</a> và phần 2 của Kafka connect thì như tiêu đề mình hôm nay mình sẽ viết bài chi tiết các bước để cấu hình lên 1 cụm Kafka Cluster chạy cho môi trường Production . </p><p>Bài này cần ae phải đã cài đặt được một Single Node của Kafka thì sẽ dễ hiểu và cấu hình hơn. Tham khảo bài viết cài đặt của mình <a href=\"https://viblo.asia/p/cai-dat-cau-hinh-zookeeper-va-kafka-tren-ubuntu-2004-chi-tiet-018J259a4YK\"> tại đây </a>  hoặc Kênh Youtube của mình tại 👉️👉️👉️👉️<br/><a href=\"https://www.youtube.com/watch?v=-EAjo27JtYA\">Link full HD </a>   😀😀😀 Cảm ơn anh em!!! </p><p>Ae chuẩn bị cho mình một ly trà không trà thì nước mát lạnh cho tỉnh táo và ngồi ngay ngắn hoặc chuẩn bị sẵn máy để vào việc nhé ae 😆😆😆😆 . </p><p>**Let's go **</p><p>Cũng giống như <a href=\"https://viblo.asia/p/cai-dat-cau-hinh-zookeeper-va-kafka-tren-ubuntu-2004-chi-tiet-018J259a4YK\">bài cài đặt</a> hôm trước  mình sẽ có danh sách như sau: </p><ol><li>Một vài thông tin yêu cầu</li><li>Setup mở port trên các máy broker</li><li>Cấu hình Zookeeper Cluster. </li><li>Cấu hình Kafka Cluster</li><li>Cài đặt Kafdrop </li><li>View và thao tác với cụm Kafka Cluster trên Kafdrop UI</li></ol><p></p><p>Đã xong phần giới thiệu ta đi bắt tay vào công việc nhé. </p><p>Trong bài viết này mình dùng 3 máy cùng 1 dải mạng </p><p>| NAME      |   IP | <br/>| --------      | -------- <br/>| vm-01     | 192.168.1.121<br />| vm-02     | 192.168.1.120 <br/>| vm-03     | 192.168.1.122</p><h3 id=\"1mtvithngtinyucu\">1. Một vài thông tin yêu cầu</h3><ul><li>Thứ nhất là về máy để cài thì cần tối thiểu là 3 máy với cấu hình tối thiểu 4GB RAM </li><li>Các máy có thể cùng hoặc không cùng trong cùng 1 dải mạng được setup mở port </li><li>Và đương nhiên là ae đã setup đủ tối thiểu 3 máy để cấu hình join lại thành 1 cụm Cluster 😆😆😆</li></ul><p>**** Lưu ý:  Khi setup Kafka Cluster sử dụng Zookeeper thì số máy Broker tham gia vào 1 cụm cluster sẽ là số lẻ  và tối thiểu là 3 máy . </p><h3 id=\"2cuhnhmportgiaccmy\">2. Cấu hình mở Port giữa các máy</h3><p>Mình sử dụng <code>ufw</code>  để mở port </p><p>Kiểm tra <code>ufw</code> có đang Active hay không </p><pre><code>sudo ufw status<br/></code></pre><p>Nếu đang ở trang thái: <code>inactive</code> thì dùng lệnh sau để active nó lên. </p><pre><code>sudo ufw enable<br/></code></pre><p>Tiếp tục mình sẽ dùng lệnh để mở 2 port 2181 của Zookeeper và 9092 cho các máy trong cùng 1 dải mạng  có thể connect được tới 2 port này. </p><p>Mở port 2181</p><pre><code>sudo ufw allow from 192.168.1.0/24 to any port 2181 proto tcp<br/></code></pre><p>Mở Port 9092</p><pre><code>sudo ufw allow from 192.168.1.0/24 to any port 9092 proto tcp<br/></code></pre><p>Hoặc có thể dùng lệnh để chi rõ IP nguồn IP đích, Port và Protocol tương ứng như sau: </p><pre><code>sudo ufw allow from 192.168.1.121 to any port 9092 proto tcp<br/></code></pre><p>👉️👉️👉️👉️ Ae thực hiện lần lượt trên từng máy còn lại nhé, bước này cũng khá quan trọng vì các máy bắt buộc phải kết nối được tới các port của nhau nhé!!!!  </p><h3 id=\"3cuhnhzookeepercluster\">3. Cấu hình Zookeeper Cluster</h3><p>Trên file <code>zookeeper.properties</code> trong thư mục <code>config</code> ở mỗi máy sau khi ae đã tải giải nén bản Relase và cài Kafka single Note. </p><p>Ở đây của mình sẽ là được dẫn <code>/home/kafka/download/kafka/config</code> </p><p>Bước 1 : Mình sẽ tạo 2 thư mục chứa data và log của thằng Zookeeper tại : </p><p><code>/home/kafka/zookeeper/logs</code></p><p><code>/home/kafka/zookeeper/data-logs</code></p><p>***  Lưu ý:  việc Kafka có bị mất data hay không nó cũng phụ thuộc vào 2 đường dẫn này nhé nên ae lưu ý khi tạo thư mục này </p><p>Bước 2: Trong thư mục    <code>/home/kafka/zookeeper/logs</code> mình sẽ tạo 1 file <code>myid</code> và sửa nội dung file sẽ chứa 1 số nguyên tùy chọn và nó sẽ là <code>id</code> của zookeeper trong cụm cluster. </p><p>Bước 3:  Mình dùng lệnh <code>vi</code> và chỉnh sửa nội dung của file  <code>zookeeper.properties</code> như sau: </p><p><img src=\"https://images.viblo.asia/073768a1-997d-49b6-ab2e-43f9a1fae0f3.png\" alt=\"image.png\" /></p><p>Mình thêm 2 tham số:  <code>dataDir</code> và  <code>dataLogDir</code> điền giá trị là 2 đường dẫn tương ứng mình đã tạo ở Bước 1 </p><pre><code>dataDir=/home/kafka/zookeeper/logs<br/> dataLogDir=/home/kafka/zookeeper/data-logs<br/></code></pre><p>các tham số <code>Port</code> mình để mặc định và </p><pre><code>  maxClientCnxns=60<br/>  admin.enableServer=false<br/></code></pre><p>Các tham số bắt buộc phải có bao gồm:  (Về các tham số này mình sẽ giải thích ở một bài sớm nhất nhé ae  😆😆😆)</p><pre><code>tickTime=2000<br/>initLimit=10<br/>syncLimit=5<br/>4lw.commands.whitelist=*<br/></code></pre><p>Tiếp theo tham số này quan trọng. </p><pre><code>server.1=192.168.1.121:2888:3888<br/>server.2=192.168.1.120:2888:3888<br/>server.3=192.168.1.122:2888:3888<br/></code></pre><p>cấu trúc của tham số trên như sau: </p><p>server.&lt;myid&gt;=&lt;hostname&gt;:&lt;leaderport&gt;:&lt;electionport&gt;</p><p><code>myid</code> nó chính là <code>id</code> trong file <code>myid</code> mình đã tạo ở Bước 2 </p><p><code>leaderport</code> : trong 1 thời điểm chỉ có 1 Zookeeper làm <code>leader</code> nên đây sẽ là <code>Port</code> để các máy follower connect tới   </p><p><code>electionport</code>: Sử dụng cho việc bình bầu follower lên làm <code>leader</code> </p><p>ở đây mình có 3 máy và có 3  nên sẽ có 3 id là 1, 2 và 3 tương ứng với 3 máy mình đã tạo ở Bước 2 . </p><p>AE tiếp tục thực hiện 3 bước này trên các máy còn lại. </p><p>Sau Khi chỉnh sửa file cấu hình xong ae thực hiện restart lại zookeeper </p><pre><code> sudo systemctl restart zookeeper.service<br/></code></pre><p>(TH ae chưa setup service systemd thì ae có thể dùng lệnh <code>zookeeper-server-stop.sh</code> <code>zookeeper-server-start.sh</code> và  trong thư mục <code>bin</code> nhé 😄)   </p><h3 id=\"4cuhnhjoinkafkacluster\">4. Cấu hình Join Kafka Cluster.</h3><p>Vẫn trong thư mục <code>config</code> trên mỗi máy </p><p>Mình sẽ <code>vi</code> file <code>server.properties</code> lên và chỉnh sửa như sau: </p><p>Các tham số quan trọng trong file cần phải cấu hình ngoài ra các tham số khác ae có thể tìm hiểu và trong khi vận hành và chỉnh sửa sao cho phù hợp. </p><p>Trên máy 192.168.1.121 của mình sửa cấu hình 1 số các tham số như sau: </p><pre><code>   broker.id=1<br/>    listeners=PLAINTEXT://0.0.0.0:9092 <br/>    advertised.listeners=PLAINTEXT://192.168.1.121:9092<br/>    log.dirs=/home/kafka/logs<br/>    zookeeper.connect=localhost:2181,192.168.1.120:2181,192.168.1.122:2181<br/></code></pre><p><strong>Lý do</strong></p><p>Khi join cluster thì các kafka node phải có id khác nhau </p><p><code>log.dirs</code>  chỗ này chứa 1 số thông tin quan trọng như meta.properties để có thể start 1 cụm cluster nên cũng cần phải cẩn thận</p><p>và 2 tha số khi để cấu hình cho các service trong cùng 1 dải mạng có thể connect tới kafka</p><p>Và Tham số quan trọng tiếp theo </p><pre><code>    zookeeper.connect=localhost:2181,192.168.1.120:2181,192.168.1.122:2181<br/></code></pre><p>Chính là tham số để connect tới cụm Cluster Zookeeper đã cấu hình ở bên trên. </p><p>AE thực hiện cấu hình các tham số bên trên với các máy còn lại </p><p>Sau khi cấu hình trên các máy xong nhớ  thực hiện   restart lại các máy Kafka nhé. </p><pre><code>systemctl restart kafka.service<br/></code></pre><p>Hoặc có thể dùng lệnh sh start, stop trong thư mục <code>bin</code></p><p>Oke Tới đây là quá trình đã gần hoàn thiện cho 1 cụm Cluster    </p><h3 id=\"5cikafdropui\">5. Cài Kafdrop UI</h3><p>Yêu cầu: máy đã cài Java JDK </p><p>Bước 1: Tạo 1 thư mục </p><pre><code>mkdir  ~/kafdrop &amp;amp;&amp;amp; cd kafdrop<br/></code></pre><p>Bước 2:  Tải file <code>jar</code> Kafdrop</p><pre><code>wget https://github.com/obsidiandynamics/kafdrop/releases/download/3.28.0/kafdrop-3.28.0.jar<br/></code></pre><p>Bước 3: tạo service systemd cho kafdrop</p><pre><code>vi /etc/systemd/system/kafdrop.service<br/></code></pre><p>Bước 4: điền thông tin file với tham số IP của các máy Kafka tương ứng </p><pre><code>   [Unit]<br/>Description=Kafdrop server<br/>Documentation=https://github.com/obsidiandynamics/kafdrop<br/>Requires=network.target remote-fs.target<br/>After=network.target remote-fs.target<br/>[Service]<br/>Type=simple<br/>ExecStart=/bin/java --add-opens=java.base/sun.nio.ch=ALL-UNNAMED \\<br/>    -jar /home/kafka/kafdrop/kafdrop-3.28.0.jar \\<br/>    --kafka.brokerConnect=localhost:9092,192.168.1.121:9092,192.168.1.120:9092 --server.port=9010 --management.server.port=9010 \\ <br/>Restart=on-abnormal<br/>[Install]<br/>WantedBy=multi-user.target<br/></code></pre><p>Bước 5: Start Kafdrop và mở Port <code>9010</code> của Kafdrop </p><pre><code>systemctl start kafdrop.service<br/> systemctl enable kafdrop.service<br/>sudo ufw allow from 192.168.1.0/24 to any port 9010 proto tcp<br/></code></pre><h3 id=\"6kimtrathnhqu\">6. Kiểm tra thành quả .</h3><p><img src=\"https://images.viblo.asia/60317460-59d7-42be-b678-db135555314e.png\" alt=\"image.png\" /></p><p>Bài viết hôm nay cũng khá dài, cảm ơn all ace đã đọc bài viết của mình nhé, Ae cho mình xin 1 Vote và chờ bài viết tiếp theo nhé </p><p>Trân thành cảm ơn anh em !</p>","title":"Cài đặt Kafka Cluster  cho môi trường Production, Sử dụng Kafdrop UI để View và thao tác","tags":["cluster","kafka","zookeeper","kafdrop","kafka cluster"],"created_at":1691833402000,"updated_at":1691983329000,"comments":[{"id":56003,"hash_id":"5OXLAlgYJGr","user_id":27812,"level":0,"points":1,"rated_value":0,"commentable_type":"Post","commentable_id":70782,"in_reply_to_comment":null,"in_reply_to_user":null,"created_at":"2023-08-12T19:45:41+07:00","updated_at":"2023-08-14T05:00:20+07:00","deleted_at":null,"edited_at":"2023-08-12T19:45:57+07:00","contents":"Kafka ui dùng Redpanda Console có vẻ tiện hơn, mình từng dùng mấy thằng nhưng thấy thằng này ổn nhất","contents_short":"Kafka ui dùng Redpanda Console có vẻ tiện hơn, mình từng dùng mấy thằng nhưng thấy thằng này ổn nhất","user":{"data":{"id":27812,"url":"https://viblo.asia/u/xdorro","avatar":"b62fe4b0-1499-4851-a0fe-7d0ca07b11ff.jpg","name":"Anh Nguyen","username":"xdorro","followers_count":0,"reputation":57,"posts_count":0,"banned_at":null,"level_partner":null}}},{"id":56004,"hash_id":"obA46XwMLKv","user_id":60533,"level":1,"points":1,"rated_value":0,"commentable_type":"Post","commentable_id":70782,"in_reply_to_comment":56003,"in_reply_to_user":"xdorro","created_at":"2023-08-12T20:02:25+07:00","updated_at":"2023-08-14T05:00:20+07:00","deleted_at":null,"edited_at":"2023-08-12T20:02:25+07:00","contents":"mình mới dùng thằng Kafdrop này và AKHQ, nào rảnh mình sẽ thử trải nghiệm Redpanda Console 😃","contents_short":"mình mới dùng thằng Kafdrop này và AKHQ, nào rảnh mình sẽ thử trải nghiệm Redpanda Console 😃","user":{"data":{"id":60533,"url":"https://viblo.asia/u/dohv","avatar":"fc4704f5-0141-4229-a144-400037a8ffa4.png","name":"dohv","username":"dohv","followers_count":13,"reputation":374,"posts_count":6,"banned_at":null,"level_partner":null}}}]}